{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize text moderator\n",
    "    text_mod = TextModerator()\n",
    "    text_mod.train_model()\n",
    "    \n",
    "    # Test text moderation\n",
    "    test_texts = [\n",
    "        \"Can someone help with homework?\",\n",
    "        \"This class is [offensive_word]\",\n",
    "        \"Meeting at library at 3 PM\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing Text Moderation:\")\n",
    "    for text in test_texts:\n",
    "        result = text_mod.check_text(text)\n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"Result: {'Safe' if result['is_safe'] else 'Unsafe'}\")\n",
    "        print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "    \n",
    "    # Initialize image moderator\n",
    "    img_mod = ImageModerator()\n",
    "    \n",
    "    # Test image moderation\n",
    "    test_images = [\n",
    "        'path/to/test_image1.jpg',\n",
    "        'path/to/test_image2.jpg'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting Image Moderation:\")\n",
    "    for img_path in test_images:\n",
    "        result = img_mod.check_image(img_path)\n",
    "        print(f\"\\nImage: {img_path}\")\n",
    "        print(f\"Result: {'Safe' if result['is_safe'] else 'Unsafe'}\")\n",
    "        print(f\"Reason: {result['reason']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
